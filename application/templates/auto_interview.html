<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <title>Auto Interview</title>
    <style>
        body { font-family: Arial, sans-serif; padding: 20px; max-width: 700px; margin: auto; }
        #videoPreview { width: 100%; max-width: 600px; border: 1px solid #ccc; }
        #question { margin: 20px 0; font-size: 1.2em; }
        button { margin: 10px 5px 20px 0; padding: 10px 20px; font-size: 1em; }
        #summary { margin-top: 40px; }
        #summary ul { list-style: none; padding: 0; }
        #summary li { margin-bottom: 10px; }
    </style>
</head>
<body>

    <h1>Auto Interview</h1>

    <video id="videoPreview" autoplay muted></video>

    <div id="question"></div>

    <button id="startBtn">Start Recording</button>
    <button id="stopBtn" disabled>Stop Recording</button>

    <div id="summary" style="display:none;">
        <h2>Interview Summary</h2>
        <ul id="summaryList"></ul>
    </div>

    <script>
        // Interview questions - you can replace these with Django template vars or API data
        const questions = [
            "Tell me about yourself.",
            "Why do you want this job?",
            "Describe a challenging situation you faced."
        ];

        let currentQuestionIndex = 0;
        let mediaRecorder;
        let recordedChunks = [];
        let stream;
        let summary = [];

        const videoPreview = document.getElementById('videoPreview');
        const questionDiv = document.getElementById('question');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const summaryDiv = document.getElementById('summary');
        const summaryList = document.getElementById('summaryList');

        // Display current question
        function showQuestion(index) {
            questionDiv.textContent = `Question ${index + 1}: ${questions[index]}`;
        }

        // Initialize webcam stream
        async function initWebcam() {
            try {
                stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
                videoPreview.srcObject = stream;
            } catch (err) {
                alert("Could not access webcam and microphone. Please allow access.");
                console.error(err);
            }
        }

        // Helper to get CSRF token from cookies (for Django POST)
        function getCookie(name) {
            const value = `; ${document.cookie}`;
            const parts = value.split(`; ${name}=`);
            if (parts.length === 2) return parts.pop().split(';').shift();
        }

        // Upload recorded video blob to backend
        async function uploadVideo(blob, questionIndex) {
            const formData = new FormData();
            formData.append('video', blob, `answer_q${questionIndex + 1}.webm`);
            formData.append('question_index', questionIndex);
            // Add interview id if available, example:
            // formData.append('interview_id', {{ interview.id }});

            try {
                const res = await fetch('/upload-answer/', {
                    method: 'POST',
                    headers: { 'X-CSRFToken': getCookie('csrftoken') },
                    body: formData
                });
                if (!res.ok) {
                    console.error('Video upload failed', await res.text());
                }
                return res.json();
            } catch (error) {
                console.error('Upload error:', error);
            }
        }

        // Send video for emotion detection (base64 encoded)
        async function analyzeEmotion(blob) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onloadend = async () => {
                    const base64data = reader.result.split(',')[1]; // Remove prefix
                    try {
                        const res = await fetch('/analyze-emotion/', {
                            method: 'POST',
                            headers: {
                                'Content-Type': 'application/json',
                                'X-CSRFToken': getCookie('csrftoken')
                            },
                            body: JSON.stringify({ video: base64data })
                        });
                        if (!res.ok) {
                            reject('Emotion analysis failed');
                        } else {
                            const data = await res.json();
                            resolve(data.emotions);
                        }
                    } catch (e) {
                        reject(e);
                    }
                };
                reader.readAsDataURL(blob);
            });
        }

        // Show summary UI
        function showSummary() {
            startBtn.style.display = 'none';
            stopBtn.style.display = 'none';
            questionDiv.style.display = 'none';
            videoPreview.style.display = 'none';

            summaryDiv.style.display = 'block';
            summaryList.innerHTML = '';

            summary.forEach((item, idx) => {
                const li = document.createElement('li');
                li.innerHTML = `<strong>Question ${idx + 1}:</strong> ${questions[idx]}<br/>
                                <strong>Detected emotions:</strong> ${JSON.stringify(item.emotions)}`;
                summaryList.appendChild(li);
            });
        }

        // Start recording handler
        startBtn.onclick = () => {
            recordedChunks = [];
            mediaRecorder = new MediaRecorder(stream);

            mediaRecorder.ondataavailable = event => {
                if (event.data.size > 0) {
                    recordedChunks.push(event.data);
                }
            };

            mediaRecorder.onstop = async () => {
                const blob = new Blob(recordedChunks, { type: 'video/webm' });
                // Upload video to backend
                await uploadVideo(blob, currentQuestionIndex);

                // Analyze emotions
                let emotions = {};
                try {
                    emotions = await analyzeEmotion(blob);
                } catch (e) {
                    console.error('Emotion analysis error:', e);
                }

                // Save summary data
                summary.push({ questionIndex: currentQuestionIndex, emotions });

                // Move to next question or finish
                currentQuestionIndex++;
                if (currentQuestionIndex < questions.length) {
                    showQuestion(currentQuestionIndex);
                    startBtn.disabled = false;
                    stopBtn.disabled = true;
                } else {
                    showSummary();
                }
            };

            mediaRecorder.start();
            startBtn.disabled = true;
            stopBtn.disabled = false;
        };

        // Stop recording handler
        stopBtn.onclick = () => {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                startBtn.disabled = true;
                stopBtn.disabled = true;
            }
        };

        // Init
        window.onload = async () => {
            await initWebcam();
            showQuestion(currentQuestionIndex);
            startBtn.disabled = false;
            stopBtn.disabled = true;
        };
    </script>

</body>
</html>
<script>
        // Ensure the browser supports MediaRecorder
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            alert("Your browser does not support video recording. Please use a modern browser.");
        }
</script>   
